import logging
import random
import re

from aiocqhttp import CQHttp

from astrbot.api.all import *
from astrbot.api.event.filter import *

logger = logging.getLogger("astrbot")

@register("astrbot_plugin_anti_porn", "buding", "ä¸€ä¸ªç”¨äºåç‘Ÿç‘Ÿçš„æ’ä»¶", "1.0.1", "https://github.com/zouyonghe/astrbot_plugin_anti_porn")
class AntiPorn(Star):
    def __init__(self, context: Context, config: dict):
        super().__init__(context)
        self.config = config

    async def _admin_check(self, event: AstrMessageEvent, client: CQHttp) -> bool:
        """æ£€æŸ¥å½“å‰ bot æ˜¯å¦æ˜¯ç¾¤ç®¡ç†å‘˜æˆ–ç¾¤ä¸»å¹¶ä¸”æ¶ˆæ¯å‘é€è€…ä¸æ˜¯ç®¡ç†å‘˜æˆ–ç¾¤ä¸»"""
        try:
            sender_id = int(event.get_sender_id())
            group_id = int(event.get_group_id())
            bot_id = int(event.get_self_id())

            bot_info = await client.get_group_member_info(group_id=group_id, user_id=bot_id, no_cache=True, self_id=int(event.get_self_id()))
            sender_info = await client.get_group_member_info(group_id=group_id, user_id=sender_id, no_cache=True, self_id=int(event.get_self_id()))
            return bot_info.get("role") in ["admin", "owner"] and sender_info.get("role") not in ["admin", "owner"]
        except Exception as e:
            logging.error(f"è·å–ç¾¤æˆå‘˜ä¿¡æ¯å¤±è´¥: {e}")
            return False

    def _in_group_white_list(self, event: AstrMessageEvent) -> bool:
        group_white_list = self.config.get("group_white_list", "").split(";")
        if str(event.get_group_id()) in group_white_list:
            logger.debug(f"ç¾¤ {event.get_group_id()} åœ¨ç™½åå•å†…ï¼Œè·³è¿‡å®¡æŸ¥")
            return True
        return False

    async def _delete_and_ban(self, event: AstrMessageEvent, message: str, client: CQHttp):
        """åˆ é™¤æ¶ˆæ¯å¹¶ç¦è¨€ç”¨æˆ·"""
        try:
            await client.delete_msg(
                message_id=int(event.message_obj.message_id),
                self_id=int(event.get_self_id())
            )
            logger.info(f"Anti porn deleted message: {message}")

            await client.set_group_ban(
                group_id=int(event.get_group_id()),
                user_id=int(event.get_sender_id()),
                duration=self.config.get("group_ban_time", 5) * 60,
                self_id=int(event.get_self_id())
            )
            logger.info(f"Banned user: {event.get_sender_id()} for 5 minutes")

        except Exception as e:
            logger.error(f"Failed to delete and ban: {e}")

        event.stop_event()

    def _local_censor_check(self, message: str) -> bool:
        local_censor_keywords = self.config.get("local_censor_keywords", "").split(";")
        # å¦‚æœæ•æ„Ÿè¯åˆ—è¡¨ä¸ºç©ºï¼Œç›´æ¥è¿”å› False æˆ–å…¶ä»–é€‚å½“çš„å¤„ç†
        if not local_censor_keywords:
            return False

        message = message.lower()
        # å»é™¤æ¶ˆæ¯ä¸­çš„æ ‡ç‚¹ç¬¦å·å’Œç©ºæ ¼
        message = re.sub(r"[^\w\u4e00-\u9fa5]", "", message)  # ä¿ç•™å­—æ¯ã€æ•°å­—å’Œä¸­æ–‡å­—ç¬¦

        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ•æ„Ÿè¯
        for keyword in local_censor_keywords:
            if keyword.lower() in message:  # æ£€æŸ¥æ•æ„Ÿè¯æ˜¯å¦åœ¨æ¶ˆæ¯ä¸­
                return True
        return False

    async def _llm_censor_check(self, event: AstrMessageEvent, message: str):
        """è°ƒç”¨ LLM è¿›è¡Œæ•æ„Ÿå†…å®¹æ£€æµ‹ï¼Œåªæœ‰åœ¨æ¶ˆæ¯å­—æ•° < 50 å¹¶ä¸”æ»¡è¶³æ¦‚ç‡è¦æ±‚æ—¶æ‰æ‰§è¡Œ"""
        llm_probability = float(self.config.get("llm_censor_probability", 0.1))
        if len(message) > 50 or random.random() > llm_probability:
            return

        """è°ƒç”¨ LLM è¿›è¡Œæ•æ„Ÿå†…å®¹æ£€æµ‹"""
        provider = self.context.get_using_provider()
        if not provider:
            logger.warning("No available LLM provider")
            return

        custom_guidelines = self.config.get("custom_guideline", "")
        censor_prompt = (
            f"Analyze the following message and determine whether it contains actual pornography or inappropriate content, "
            f"considering the overall context. Do not judge based on isolated words or phrases. "
            f"Additionally, consider the following user-defined guidelines when making your judgment:"
            f"{custom_guidelines}\n\n"
            f"Answer only 'Yes' or 'No' with no additional explanation.\n\n"
            f"Message: {message}"
        )

        try:
            response = await provider.text_chat(censor_prompt, session_id=str(event.get_sender_id()))
            if response and response.completion_text:
                result = response.completion_text.strip().lower()
                return result.startswith("yes") or result.endswith("yes")

        except Exception as e:
            logger.error(f"LLM censor request failed: {e}")

        return

    @event_message_type(EventMessageType.GROUP_MESSAGE, priority=10)
    async def sensor_porn(self, event: AstrMessageEvent):
        """æ£€æµ‹æ¶ˆæ¯æ˜¯å¦åŒ…å«æ•æ„Ÿå†…å®¹"""
        if not self.config.get("enable_anti_porn", False):
            return

        if not self._in_group_white_list(event):
            return

        from astrbot.core.platform.sources.aiocqhttp.aiocqhttp_message_event import AiocqhttpMessageEvent
        assert isinstance(event, AiocqhttpMessageEvent)
        client = event.bot
        # æ£€æŸ¥botä¸ºç®¡ç†å‘˜ï¼Œæ¶ˆæ¯å‘é€è€…ä¸ä¸ºç®¡ç†å‘˜
        if not await self._admin_check(event, client):
            logging.debug("Bot ä¸æ˜¯è¯¥ç¾¤ç®¡ç†å‘˜ï¼Œæ— éœ€æ£€æµ‹ç¾¤èŠæ˜¯å¦åˆè§„")
            return

        for comp in event.get_messages():
            if isinstance(comp, BaseMessageComponent):
                message_content = comp.toString()
                logger.debug(f"Text message content: {message_content}")
                # æœ¬åœ°æ£€æŸ¥
                if self._local_censor_check(message_content):
                    logger.debug(f"Local sensor found illegal message: {message_content}")
                    await self._delete_and_ban(event, message_content, client)
                    return

                # è°ƒç”¨LLMæ£€æµ‹
                if await self._llm_censor_check(event, message_content):
                    logger.debug(f"LLM censor found illegal message: {message_content}")
                    await self._delete_and_ban(event, message_content, client)
                    return

    @command_group("anti_porn")
    def anti_porn(self):
        pass

    @permission_type(PermissionType.ADMIN)
    @anti_porn.command("enable")
    async def enable_anti_porn(self, event: AstrMessageEvent):
        """å¼€å¯åç‘Ÿç‘Ÿæ¨¡å¼"""
        try:
            if self.config.get("enable_anti_porn", False):
                yield event.plain_result("âœ… åç‘Ÿç‘Ÿæ¨¡å¼å·²ç»æ˜¯å¼€å¯çŠ¶æ€")
                return

            self.config["enable_anti_porn"] = True
            yield event.plain_result("ğŸ“¢ åç‘Ÿç‘Ÿæ¨¡å¼å·²å¼€å¯")
        except Exception as e:
            logger.error(f"å¼€å¯åç‘Ÿç‘Ÿæ¨¡å¼å¤±è´¥: {e}")
            yield event.plain_result("âŒ å¼€å¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")

    @permission_type(PermissionType.ADMIN)
    @anti_porn.command("disable")
    async def disable_anti_porn(self, event: AstrMessageEvent):
        """å…³é—­åç‘Ÿç‘Ÿæ¨¡å¼"""
        try:
            if not self.config.get("enable_anti_porn", False):
                yield event.plain_result("âœ… åç‘Ÿç‘Ÿæ¨¡å¼å·²ç»æ˜¯å…³é—­çŠ¶æ€")
                return

            self.config["enable_anti_porn"] = False
            yield event.plain_result("ğŸ“¢ åç‘Ÿç‘Ÿæ¨¡å¼å·²å…³é—­")
        except Exception as e:
            logger.error(f"å…³é—­åç‘Ÿç‘Ÿæ¨¡å¼å¤±è´¥: {e}")
            yield event.plain_result("âŒ å…³é—­å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")

    @permission_type(PermissionType.ADMIN)
    @anti_porn.command("add")
    async def add_to_white_list(self, event: AstrMessageEvent, group_num: str):
        """æ·»åŠ ç¾¤ç»„åˆ°ç™½åå•"""
        try:
            group_white_list = self.config.get("group_white_list", "").split(";")
            if group_num in group_white_list:
                yield event.plain_result(f"âœ… ç¾¤ {group_num} å·²åœ¨ç™½åå•ä¸­")
                return

            group_white_list.append(group_num)
            self.config["group_white_list"] = ";".join(filter(None, group_white_list))
            yield event.plain_result(f"âœ… ç¾¤ {group_num} å·²æ·»åŠ åˆ°ç™½åå•")
        except Exception as e:
            logger.error(f"æ·»åŠ ç¾¤ç»„åˆ°ç™½åå•å¤±è´¥: {e}")
            yield event.plain_result("âŒ æ·»åŠ å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")

    @permission_type(PermissionType.ADMIN)
    @anti_porn.command("del")
    async def del_from_white_list(self, event: AstrMessageEvent, group_num: str):
        """ä»ç™½åå•ä¸­åˆ é™¤ç¾¤ç»„"""
        try:
            group_white_list = self.config.get("group_white_list", "").split(";")
            if group_num not in group_white_list:
                yield event.plain_result(f"âš ï¸ ç¾¤ {group_num} ä¸åœ¨ç™½åå•ä¸­")
                return

            group_white_list.remove(group_num)
            self.config["group_white_list"] = ";".join(filter(None, group_white_list))
            yield event.plain_result(f"âœ… ç¾¤ {group_num} å·²ä»ç™½åå•ä¸­ç§»é™¤")
        except Exception as e:
            logger.error(f"ä»ç™½åå•åˆ é™¤ç¾¤ç»„å¤±è´¥: {e}")
            yield event.plain_result("âŒ åˆ é™¤å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")

    @permission_type(PermissionType.ADMIN)
    @anti_porn.command("list")
    async def list_white_list(self, event: AstrMessageEvent):
        """æŸ¥è¯¢ç™½åå•åˆ—è¡¨"""
        try:
            group_white_list = self.config.get("group_white_list", "").split(";")
            if not group_white_list or all(not g.strip() for g in group_white_list):
                yield event.plain_result("ğŸ“œ ç›®å‰ç™½åå•ä¸ºç©º")
                return

            white_list_str = "\n".join(group_white_list)
            yield event.plain_result(f"ğŸ“œ å½“å‰ç™½åå•ç¾¤ç»„:\n{white_list_str}")
        except Exception as e:
            logger.error(f"æŸ¥è¯¢ç™½åå•å¤±è´¥: {e}")
            yield event.plain_result("âŒ æŸ¥è¯¢å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
