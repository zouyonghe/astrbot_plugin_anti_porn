import logging
import random

from astrbot.api.event.filter import *
from aiocqhttp import CQHttp

from astrbot.api.all import *

logger = logging.getLogger("astrbot")

@register("astrbot_plugin_anti_porn", "buding", "ä¸€ä¸ªç”¨äºåç‘Ÿç‘Ÿçš„æ’ä»¶", "1.0.0", "https://github.com/zouyonghe/astrbot_plugin_anti_porn")
class AntiPorn(Star):
    def __init__(self, context: Context, config: dict, bot: CQHttp):
        super().__init__(context)
        self.bot = bot
        self.config = config

    async def _is_self_admin(self, event: AstrMessageEvent) -> bool:
        """æ£€æŸ¥å½“å‰ bot æ˜¯å¦æ˜¯ç¾¤ç®¡ç†å‘˜æˆ–ç¾¤ä¸»"""
        try:
            self_id = int(event.get_self_id())
            group_id = int(event.get_group_id())
            member_info = await self.bot.api.get_group_member_info(group_id=group_id, user_id=self_id)
            return member_info.get("role") in ["admin", "owner"]
        except Exception as e:
            logging.error(f"è·å–ç¾¤æˆå‘˜ä¿¡æ¯å¤±è´¥: {e}")
            return False

    async def _delete_and_ban(self, event: AstrMessageEvent, message: str):
        """åˆ é™¤æ¶ˆæ¯å¹¶ç¦è¨€ç”¨æˆ·"""
        try:
            await self.bot.api.delete_msg(
                message_id=int(event.message_obj.message_id),
                self_id=int(event.get_self_id())
            )
            logger.debug(f"Anti porn deleted message: {message}")

            await self.bot.api.set_group_ban(
                group_id=int(event.get_group_id()),
                user_id=int(event.get_sender_id()),
                duration=5 * 60,
                self_id=int(event.get_self_id())
            )
            logger.debug(f"Banned user: {event.get_sender_id()} for 5 minutes")

        except Exception as e:
            logger.error(f"Failed to delete and ban: {e}")

        await event.stop_event()

    async def _local_censor_check(self, message: str) -> bool:
        """æœ¬åœ°å…³é”®å­—æ£€æµ‹"""
        local_censor_keywords = self.config.get("local_censor_keywords", "").split(";")
        return any(keyword in message for keyword in local_censor_keywords)

    async def _llm_censor_check(self, event: AstrMessageEvent, message: str) -> bool:
        """è°ƒç”¨ LLM è¿›è¡Œæ•æ„Ÿå†…å®¹æ£€æµ‹ï¼Œåªæœ‰åœ¨æ¶ˆæ¯å­—æ•° < 50 å¹¶ä¸”æ»¡è¶³æ¦‚ç‡è¦æ±‚æ—¶æ‰æ‰§è¡Œ"""
        llm_probability = float(self.config.get("llm_censor_probability", 0.1))
        if len(message) > 50 or random.random() > llm_probability:
            return False

        """è°ƒç”¨ LLM è¿›è¡Œæ•æ„Ÿå†…å®¹æ£€æµ‹"""
        provider = self.context.get_using_provider()
        if not provider:
            logger.warning("No available LLM provider")
            return False

        censor_prompt = (
            f"Does the following message contain pornography or inappropriate content? "
            f"Answer only 'Yes' or 'No' with no additional explanation.\n\n"
            f"Message: {message}"
        )

        try:
            response = await provider.text_chat(censor_prompt, session_id=str(event.get_sender_id()))
            if response and response.completion_text:
                result = response.completion_text.strip().lower()
                return result.startswith("yes") or result.endswith("yes")

        except Exception as e:
            logger.error(f"LLM censor request failed: {e}")

        return False

    @event_message_type(EventMessageType.ALL)
    async def sensor_porn(self, event: AstrMessageEvent):
        """æ£€æµ‹æ¶ˆæ¯æ˜¯å¦åŒ…å«æ•æ„Ÿå†…å®¹"""

        # æ£€æŸ¥ Bot æ˜¯å¦ä¸ºç®¡ç†å‘˜
        if not await self._is_self_admin(event):
            logging.debug("Bot ä¸æ˜¯è¯¥ç¾¤ç®¡ç†å‘˜ï¼Œæ— éœ€æ£€æµ‹ç¾¤èŠæ˜¯å¦åˆè§„")
            return

        for comp in event.get_messages():
            if isinstance(comp, BaseMessageComponent):
                message_content = comp.toString()

                # æœ¬åœ°æ£€æŸ¥
                if await self._local_censor_check(message_content):
                    logger.debug(f"Local sensor found illegal message: {message_content}")
                    await self._delete_and_ban(event, message_content)
                    return

                # è°ƒç”¨LLMæ£€æµ‹
                if await self._llm_censor_check(event, message_content):
                    logger.debug(f"LLM censor found illegal message: {message_content}")
                    await self._delete_and_ban(event, message_content)
                    return

    @permission_type(PermissionType.ADMIN)
    @command("anti_porn")
    async def anti_porn(self, event: AstrMessageEvent):
        """åˆ‡æ¢åç‘Ÿç‘Ÿæ¨¡å¼ï¼ˆenable_anti_pornï¼‰"""
        try:
            # è¯»å–å½“å‰çŠ¶æ€å¹¶å–å
            current_set = bool(self.config.get("enable_anti_porn", False))
            new_set = not current_set

            # æ›´æ–°é…ç½®
            self.config["enable_anti_porn"] = new_set

            # å‘é€åé¦ˆæ¶ˆæ¯
            status = "å¼€å¯" if new_set else "å…³é—­"
            yield event.plain_result(f"ğŸ“¢ åç‘Ÿç‘Ÿæ¨¡å¼å·²{status}")
        except Exception as e:
            logger.error(f"åˆ‡æ¢åç‘Ÿç‘Ÿæ¨¡å¼å¤±è´¥: {e}")
            yield event.plain_result("âŒ åˆ‡æ¢åç‘Ÿç‘Ÿæ¨¡å¼å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
